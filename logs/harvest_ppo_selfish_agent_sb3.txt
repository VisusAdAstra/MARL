nohup: ignoring input
/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/ale_py/roms/__init__.py:84: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management
  __all__ = _resolve_roms()
Using cuda:2 device
Using cuda:2 device
Using cuda:2 device
Using cuda:2 device
Using cuda:2 device
start training 2025-04-14 20:11:50.977948
Arguments successfully written to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3/config.yaml
Logging to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3_1
Logging to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3_1/policy_1
Logging to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3_1/policy_2
Logging to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3_1/policy_3
Logging to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3_1/policy_4
Logging to ./results/sb3/ppo_independent/harvest_ppo_selfish_agent_sb3_1/policy_5
---------------------------------
| policy_id          | 0        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -657     |
| time/              |          |
|    fps             | 551      |
|    iterations      | 32000    |
|    time_elapsed    | 58       |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| policy_id          | 1        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -659     |
| time/              |          |
|    fps             | 467      |
|    iterations      | 32000    |
|    time_elapsed    | 68       |
|    total_timesteps | 32000    |
---------------------------------
Early stopping at step 13 due to reaching max kl: 0.02
---------------------------------
| policy_id          | 2        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -694     |
| time/              |          |
|    fps             | 435      |
|    iterations      | 32000    |
|    time_elapsed    | 73       |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| policy_id          | 3        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -665     |
| time/              |          |
|    fps             | 382      |
|    iterations      | 32000    |
|    time_elapsed    | 83       |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| policy_id          | 4        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -602     |
| time/              |          |
|    fps             | 340      |
|    iterations      | 32000    |
|    time_elapsed    | 94       |
|    total_timesteps | 32000    |
---------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -696        |
| time/                   |             |
|    fps                  | 394         |
|    iterations           | 64000       |
|    time_elapsed         | 162         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.013567649 |
|    clip_fraction        | 0.0161      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -0.000168   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.48e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 7.11e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -731        |
| time/                   |             |
|    fps                  | 371         |
|    iterations           | 64000       |
|    time_elapsed         | 172         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.014999667 |
|    clip_fraction        | 0.0116      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.000125    |
|    learning_rate        | 0.0001      |
|    loss                 | 4.21e+03    |
|    n_updates            | 14          |
|    policy_gradient_loss | -0.00153    |
|    value_loss           | 8.5e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -720        |
| time/                   |             |
|    fps                  | 351         |
|    iterations           | 64000       |
|    time_elapsed         | 182         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.013600996 |
|    clip_fraction        | 0.00893     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -7.51e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.99e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.000897   |
|    value_loss           | 8.08e+03    |
-----------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -691         |
| time/                   |              |
|    fps                  | 336          |
|    iterations           | 64000        |
|    time_elapsed         | 190          |
|    total_timesteps      | 64000        |
| train/                  |              |
|    approx_kl            | 0.0132609345 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.000141     |
|    learning_rate        | 0.0001       |
|    loss                 | 3.89e+03     |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00156     |
|    value_loss           | 8.14e+03     |
------------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -626        |
| time/                   |             |
|    fps                  | 318         |
|    iterations           | 64000       |
|    time_elapsed         | 200         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.013992669 |
|    clip_fraction        | 0.013       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 7.23e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 3.09e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00126    |
|    value_loss           | 6.48e+03    |
-----------------------------------------
----------------------------------------
| policy_id               | 0          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -630       |
| time/                   |            |
|    fps                  | 353        |
|    iterations           | 96000      |
|    time_elapsed         | 271        |
|    total_timesteps      | 96000      |
| train/                  |            |
|    approx_kl            | 0.01147398 |
|    clip_fraction        | 0.0157     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.06      |
|    explained_variance   | -4.1e-05   |
|    learning_rate        | 0.0001     |
|    loss                 | 4.22e+03   |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.00147   |
|    value_loss           | 8.59e+03   |
----------------------------------------
Early stopping at step 16 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -667        |
| time/                   |             |
|    fps                  | 345         |
|    iterations           | 96000       |
|    time_elapsed         | 277         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.009460672 |
|    clip_fraction        | 0.00926     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -0.000128   |
|    learning_rate        | 0.0001      |
|    loss                 | 5.39e+03    |
|    n_updates            | 44          |
|    policy_gradient_loss | -0.000845   |
|    value_loss           | 1.08e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -645        |
| time/                   |             |
|    fps                  | 333         |
|    iterations           | 96000       |
|    time_elapsed         | 287         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.014969211 |
|    clip_fraction        | 0.0121      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 3.58e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 4.27e+03    |
|    n_updates            | 56          |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 8.65e+03    |
-----------------------------------------
Early stopping at step 28 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -651        |
| time/                   |             |
|    fps                  | 323         |
|    iterations           | 96000       |
|    time_elapsed         | 296         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.012684066 |
|    clip_fraction        | 0.012       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -9.72e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.85e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00127    |
|    value_loss           | 7.76e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -570        |
| time/                   |             |
|    fps                  | 312         |
|    iterations           | 96000       |
|    time_elapsed         | 306         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.012047732 |
|    clip_fraction        | 0.0102      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -3.66e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.65e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00103    |
|    value_loss           | 7.55e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -552        |
| time/                   |             |
|    fps                  | 341         |
|    iterations           | 128000      |
|    time_elapsed         | 374         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.015152744 |
|    clip_fraction        | 0.0392      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -1.87e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.51e+03    |
|    n_updates            | 77          |
|    policy_gradient_loss | -0.00293    |
|    value_loss           | 5.03e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -557        |
| time/                   |             |
|    fps                  | 331         |
|    iterations           | 128000      |
|    time_elapsed         | 385         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.009981476 |
|    clip_fraction        | 0.0175      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | -1.5e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 2.95e+03    |
|    n_updates            | 74          |
|    policy_gradient_loss | -0.00123    |
|    value_loss           | 5.8e+03     |
-----------------------------------------
Early stopping at step 26 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -520        |
| time/                   |             |
|    fps                  | 324         |
|    iterations           | 128000      |
|    time_elapsed         | 395         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.015005189 |
|    clip_fraction        | 0.0159      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -4.53e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.14e+03    |
|    n_updates            | 85          |
|    policy_gradient_loss | -0.00144    |
|    value_loss           | 4.34e+03    |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -559         |
| time/                   |              |
|    fps                  | 315          |
|    iterations           | 128000       |
|    time_elapsed         | 405          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0121099595 |
|    clip_fraction        | 0.0163       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -3.46e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 2.4e+03      |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 4.72e+03     |
------------------------------------------
Early stopping at step 20 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -540        |
| time/                   |             |
|    fps                  | 310         |
|    iterations           | 128000      |
|    time_elapsed         | 412         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.013416819 |
|    clip_fraction        | 0.0356      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | -7.51e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.76e+03    |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00283    |
|    value_loss           | 3.59e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -470        |
| time/                   |             |
|    fps                  | 332         |
|    iterations           | 160000      |
|    time_elapsed         | 481         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.011770764 |
|    clip_fraction        | 0.0163      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -5.84e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.77e+03    |
|    n_updates            | 107         |
|    policy_gradient_loss | -0.00135    |
|    value_loss           | 3.59e+03    |
-----------------------------------------
Early stopping at step 20 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -452        |
| time/                   |             |
|    fps                  | 327         |
|    iterations           | 160000      |
|    time_elapsed         | 488         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.015061809 |
|    clip_fraction        | 0.0264      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | -5.25e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 865         |
|    n_updates            | 101         |
|    policy_gradient_loss | -0.002      |
|    value_loss           | 1.78e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -450        |
| time/                   |             |
|    fps                  | 320         |
|    iterations           | 160000      |
|    time_elapsed         | 499         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.012807893 |
|    clip_fraction        | 0.0215      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | -1.01e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.03e+03    |
|    n_updates            | 115         |
|    policy_gradient_loss | -0.00161    |
|    value_loss           | 2.04e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -472        |
| time/                   |             |
|    fps                  | 313         |
|    iterations           | 160000      |
|    time_elapsed         | 509         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.015255332 |
|    clip_fraction        | 0.0214      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 5.25e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 1.15e+03    |
|    n_updates            | 111         |
|    policy_gradient_loss | -0.00172    |
|    value_loss           | 2.3e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -464        |
| time/                   |             |
|    fps                  | 307         |
|    iterations           | 160000      |
|    time_elapsed         | 520         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.014437653 |
|    clip_fraction        | 0.0119      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -9.89e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.64e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00122    |
|    value_loss           | 3.31e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -419        |
| time/                   |             |
|    fps                  | 325         |
|    iterations           | 192000      |
|    time_elapsed         | 589         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.015084282 |
|    clip_fraction        | 0.0303      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -3.1e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 2.08e+03    |
|    n_updates            | 128         |
|    policy_gradient_loss | -0.00261    |
|    value_loss           | 4.06e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -381        |
| time/                   |             |
|    fps                  | 320         |
|    iterations           | 192000      |
|    time_elapsed         | 599         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.012498274 |
|    clip_fraction        | 0.0111      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 1.69e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 1.49e+03    |
|    n_updates            | 131         |
|    policy_gradient_loss | -0.00106    |
|    value_loss           | 2.99e+03    |
-----------------------------------------
Early stopping at step 26 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -380        |
| time/                   |             |
|    fps                  | 315         |
|    iterations           | 192000      |
|    time_elapsed         | 608         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.013364818 |
|    clip_fraction        | 0.0269      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | -4.41e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.19e+03    |
|    n_updates            | 145         |
|    policy_gradient_loss | -0.00225    |
|    value_loss           | 4.43e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -408        |
| time/                   |             |
|    fps                  | 310         |
|    iterations           | 192000      |
|    time_elapsed         | 618         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.012375574 |
|    clip_fraction        | 0.0169      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -7.87e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.44e+03    |
|    n_updates            | 141         |
|    policy_gradient_loss | -0.00133    |
|    value_loss           | 2.96e+03    |
-----------------------------------------
Early stopping at step 28 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -424        |
| time/                   |             |
|    fps                  | 305         |
|    iterations           | 192000      |
|    time_elapsed         | 628         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.010036417 |
|    clip_fraction        | 0.0138      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -1.39e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.64e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00122    |
|    value_loss           | 3.31e+03    |
-----------------------------------------
Early stopping at step 26 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -369        |
| time/                   |             |
|    fps                  | 320         |
|    iterations           | 224000      |
|    time_elapsed         | 697         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.014129855 |
|    clip_fraction        | 0.0142      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -1.13e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.27e+03    |
|    n_updates            | 158         |
|    policy_gradient_loss | -0.00131    |
|    value_loss           | 2.55e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -372        |
| time/                   |             |
|    fps                  | 316         |
|    iterations           | 224000      |
|    time_elapsed         | 707         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.015019279 |
|    clip_fraction        | 0.035       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -5.72e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 963         |
|    n_updates            | 158         |
|    policy_gradient_loss | -0.00249    |
|    value_loss           | 1.88e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -364        |
| time/                   |             |
|    fps                  | 312         |
|    iterations           | 224000      |
|    time_elapsed         | 717         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.014616562 |
|    clip_fraction        | 0.0173      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -1.11e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 933         |
|    n_updates            | 175         |
|    policy_gradient_loss | -0.00141    |
|    value_loss           | 1.88e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -348        |
| time/                   |             |
|    fps                  | 307         |
|    iterations           | 224000      |
|    time_elapsed         | 727         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.014940929 |
|    clip_fraction        | 0.0157      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -4.77e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.57e+03    |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00144    |
|    value_loss           | 3.26e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -358        |
| time/                   |             |
|    fps                  | 303         |
|    iterations           | 224000      |
|    time_elapsed         | 738         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.015074391 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -1.81e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.14e+03    |
|    n_updates            | 177         |
|    policy_gradient_loss | -0.00216    |
|    value_loss           | 2.24e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -300        |
| time/                   |             |
|    fps                  | 316         |
|    iterations           | 256000      |
|    time_elapsed         | 810         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.013788769 |
|    clip_fraction        | 0.0303      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -4.05e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 903         |
|    n_updates            | 188         |
|    policy_gradient_loss | -0.0022     |
|    value_loss           | 1.81e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -302        |
| time/                   |             |
|    fps                  | 312         |
|    iterations           | 256000      |
|    time_elapsed         | 820         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.012053503 |
|    clip_fraction        | 0.0188      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -1.75e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 987         |
|    n_updates            | 188         |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 1.96e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -296        |
| time/                   |             |
|    fps                  | 308         |
|    iterations           | 256000      |
|    time_elapsed         | 830         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.007950513 |
|    clip_fraction        | 0.0112      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -1e-05      |
|    learning_rate        | 0.0001      |
|    loss                 | 771         |
|    n_updates            | 205         |
|    policy_gradient_loss | -0.00094    |
|    value_loss           | 1.55e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -286        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 256000      |
|    time_elapsed         | 840         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.013742456 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -1.14e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 587         |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 1.16e+03    |
-----------------------------------------
Early stopping at step 19 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -305        |
| time/                   |             |
|    fps                  | 302         |
|    iterations           | 256000      |
|    time_elapsed         | 847         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.014012966 |
|    clip_fraction        | 0.0316      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -1.31e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 842         |
|    n_updates            | 207         |
|    policy_gradient_loss | -0.00182    |
|    value_loss           | 1.66e+03    |
-----------------------------------------
----------------------------------------
| policy_id               | 0          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -243       |
| time/                   |            |
|    fps                  | 313        |
|    iterations           | 288000     |
|    time_elapsed         | 919        |
|    total_timesteps      | 288000     |
| train/                  |            |
|    approx_kl            | 0.01318475 |
|    clip_fraction        | 0.0163     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.94      |
|    explained_variance   | -1.91e-06  |
|    learning_rate        | 0.0001     |
|    loss                 | 686        |
|    n_updates            | 218        |
|    policy_gradient_loss | -0.00131   |
|    value_loss           | 1.35e+03   |
----------------------------------------
----------------------------------------
| policy_id               | 1          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -251       |
| time/                   |            |
|    fps                  | 309        |
|    iterations           | 288000     |
|    time_elapsed         | 930        |
|    total_timesteps      | 288000     |
| train/                  |            |
|    approx_kl            | 0.00978399 |
|    clip_fraction        | 0.0111     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.98      |
|    explained_variance   | -1.07e-06  |
|    learning_rate        | 0.0001     |
|    loss                 | 508        |
|    n_updates            | 218        |
|    policy_gradient_loss | -0.000872  |
|    value_loss           | 1.03e+03   |
----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -265        |
| time/                   |             |
|    fps                  | 305         |
|    iterations           | 288000      |
|    time_elapsed         | 941         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.010807384 |
|    clip_fraction        | 0.00984     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -9.18e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 742         |
|    n_updates            | 235         |
|    policy_gradient_loss | -0.000884   |
|    value_loss           | 1.53e+03    |
-----------------------------------------
Early stopping at step 19 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -210        |
| time/                   |             |
|    fps                  | 303         |
|    iterations           | 288000      |
|    time_elapsed         | 948         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.014802477 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 2.32e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 542         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00183    |
|    value_loss           | 1.1e+03     |
-----------------------------------------
Early stopping at step 21 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -283        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 288000      |
|    time_elapsed         | 955         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.010398118 |
|    clip_fraction        | 0.00536     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -1.32e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 741         |
|    n_updates            | 237         |
|    policy_gradient_loss | -0.000675   |
|    value_loss           | 1.5e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -196        |
| time/                   |             |
|    fps                  | 311         |
|    iterations           | 320000      |
|    time_elapsed         | 1026        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.014486132 |
|    clip_fraction        | 0.0216      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | -3.34e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 446         |
|    n_updates            | 248         |
|    policy_gradient_loss | -0.00158    |
|    value_loss           | 905         |
-----------------------------------------
Early stopping at step 21 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -194        |
| time/                   |             |
|    fps                  | 309         |
|    iterations           | 320000      |
|    time_elapsed         | 1033        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.011695597 |
|    clip_fraction        | 0.0203      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -3.7e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 359         |
|    n_updates            | 248         |
|    policy_gradient_loss | -0.00135    |
|    value_loss           | 716         |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -220         |
| time/                   |              |
|    fps                  | 306          |
|    iterations           | 320000       |
|    time_elapsed         | 1045         |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0149722705 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 5.3e-06      |
|    learning_rate        | 0.0001       |
|    loss                 | 455          |
|    n_updates            | 255          |
|    policy_gradient_loss | -0.00152     |
|    value_loss           | 892          |
------------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -165        |
| time/                   |             |
|    fps                  | 303         |
|    iterations           | 320000      |
|    time_elapsed         | 1055        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.015033339 |
|    clip_fraction        | 0.0171      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | -5.01e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 506         |
|    n_updates            | 242         |
|    policy_gradient_loss | -0.0012     |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -240        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 320000      |
|    time_elapsed         | 1066        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.011225557 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -3.22e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 875         |
|    n_updates            | 267         |
|    policy_gradient_loss | -0.00184    |
|    value_loss           | 1.7e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -158        |
| time/                   |             |
|    fps                  | 309         |
|    iterations           | 352000      |
|    time_elapsed         | 1137        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.015154493 |
|    clip_fraction        | 0.0252      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 5.72e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 371         |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00186    |
|    value_loss           | 759         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -157        |
| time/                   |             |
|    fps                  | 306         |
|    iterations           | 352000      |
|    time_elapsed         | 1147        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.013157291 |
|    clip_fraction        | 0.0236      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -2.86e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 346         |
|    n_updates            | 278         |
|    policy_gradient_loss | -0.0017     |
|    value_loss           | 698         |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -153         |
| time/                   |              |
|    fps                  | 304          |
|    iterations           | 352000       |
|    time_elapsed         | 1157         |
|    total_timesteps      | 352000       |
| train/                  |              |
|    approx_kl            | 0.0150190545 |
|    clip_fraction        | 0.0271       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | -1.17e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 375          |
|    n_updates            | 281          |
|    policy_gradient_loss | -0.00179     |
|    value_loss           | 761          |
------------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 352000      |
|    time_elapsed         | 1168        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.011008531 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | -1.48e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 313         |
|    n_updates            | 272         |
|    policy_gradient_loss | -0.00153    |
|    value_loss           | 638         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -189        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 352000      |
|    time_elapsed         | 1180        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.010261934 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -4.17e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 338         |
|    n_updates            | 297         |
|    policy_gradient_loss | -0.000759   |
|    value_loss           | 665         |
-----------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -138        |
| time/                   |             |
|    fps                  | 306         |
|    iterations           | 384000      |
|    time_elapsed         | 1251        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.013196316 |
|    clip_fraction        | 0.0248      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | -2.34e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 347         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00185    |
|    value_loss           | 685         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -141        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 384000      |
|    time_elapsed         | 1261        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.011153366 |
|    clip_fraction        | 0.0102      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -9.42e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 273         |
|    n_updates            | 308         |
|    policy_gradient_loss | -0.00105    |
|    value_loss           | 550         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -117        |
| time/                   |             |
|    fps                  | 302         |
|    iterations           | 384000      |
|    time_elapsed         | 1271        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.008830945 |
|    clip_fraction        | 0.0162      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -2.74e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 262         |
|    n_updates            | 311         |
|    policy_gradient_loss | -0.00139    |
|    value_loss           | 517         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -119        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 384000      |
|    time_elapsed         | 1281        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.012369213 |
|    clip_fraction        | 0.0214      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | -6.56e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 342         |
|    n_updates            | 302         |
|    policy_gradient_loss | -0.00198    |
|    value_loss           | 679         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -149        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 384000      |
|    time_elapsed         | 1291        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.015013502 |
|    clip_fraction        | 0.00993     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | -3.81e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 327         |
|    n_updates            | 323         |
|    policy_gradient_loss | -0.000882   |
|    value_loss           | 662         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -109        |
| time/                   |             |
|    fps                  | 305         |
|    iterations           | 416000      |
|    time_elapsed         | 1363        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.008687867 |
|    clip_fraction        | 0.00478     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 5.25e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 308         |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.000539   |
|    value_loss           | 612         |
-----------------------------------------
Early stopping at step 10 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -127        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 416000      |
|    time_elapsed         | 1367        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.009780881 |
|    clip_fraction        | 0.00855     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -1.48e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 258         |
|    n_updates            | 338         |
|    policy_gradient_loss | -0.000826   |
|    value_loss           | 538         |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -92.9        |
| time/                   |              |
|    fps                  | 301          |
|    iterations           | 416000       |
|    time_elapsed         | 1377         |
|    total_timesteps      | 416000       |
| train/                  |              |
|    approx_kl            | 0.0128423115 |
|    clip_fraction        | 0.0221       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.86        |
|    explained_variance   | -3.93e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 185          |
|    n_updates            | 341          |
|    policy_gradient_loss | -0.00196     |
|    value_loss           | 381          |
------------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -102        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 416000      |
|    time_elapsed         | 1387        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.007459929 |
|    clip_fraction        | 0.0149      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 6.91e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 333         |
|    n_updates            | 332         |
|    policy_gradient_loss | -0.00107    |
|    value_loss           | 680         |
-----------------------------------------
Early stopping at step 7 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -131        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 416000      |
|    time_elapsed         | 1389        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.008592382 |
|    clip_fraction        | 0.0167      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | -2.38e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 325         |
|    n_updates            | 353         |
|    policy_gradient_loss | -0.00124    |
|    value_loss           | 650         |
-----------------------------------------
Command terminated by signal 9
861.70user Process Process-4:
Traceback (most recent call last):
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 33, in async_loop
    instr = pipe.recv()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 68, in async_loop
    pipe.send((e, tb))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
185.64system 23:54.53elapsed 73%CPU (0avgtext+0avgdata 4590828maxresident)k
0inputs+1096outputs (186major+10899071minor)pagefaults 0swaps
Process Process-3:
Traceback (most recent call last):
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 33, in async_loop
    instr = pipe.recv()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 68, in async_loop
    pipe.send((e, tb))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process Process-2:
Traceback (most recent call last):
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 33, in async_loop
    instr = pipe.recv()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 68, in async_loop
    pipe.send((e, tb))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process Process-1:
Traceback (most recent call last):
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 33, in async_loop
    instr = pipe.recv()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/supersuit/vector/multiproc_vec.py", line 68, in async_loop
    pipe.send((e, tb))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
