nohup: ignoring input
/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/ale_py/roms/__init__.py:84: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management
  __all__ = _resolve_roms()
Using cuda:1 device
Using cuda:1 device
Using cuda:1 device
Using cuda:1 device
Using cuda:1 device
start training 2025-04-16 15:29:54.086364
Arguments successfully written to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3/config.yaml
Logging to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3_2
Logging to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3_2/policy_1
Logging to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3_2/policy_2
Logging to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3_2/policy_3
Logging to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3_2/policy_4
Logging to ./results/sb3/ppo_independent/cleanup_ppo_selfish_agent_sb3_2/policy_5
----------------------------------
| policy_id          | 0         |
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -1.02e+03 |
| time/              |           |
|    fps             | 474       |
|    iterations      | 32000     |
|    time_elapsed    | 67        |
|    total_timesteps | 32000     |
----------------------------------
----------------------------------
| policy_id          | 1         |
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -1.01e+03 |
| time/              |           |
|    fps             | 402       |
|    iterations      | 32000     |
|    time_elapsed    | 79        |
|    total_timesteps | 32000     |
----------------------------------
---------------------------------
| policy_id          | 2        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -877     |
| time/              |          |
|    fps             | 355      |
|    iterations      | 32000    |
|    time_elapsed    | 89       |
|    total_timesteps | 32000    |
---------------------------------
Early stopping at step 29 due to reaching max kl: 0.02
---------------------------------
| policy_id          | 3        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -862     |
| time/              |          |
|    fps             | 319      |
|    iterations      | 32000    |
|    time_elapsed    | 100      |
|    total_timesteps | 32000    |
---------------------------------
----------------------------------
| policy_id          | 4         |
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -1.05e+03 |
| time/              |           |
|    fps             | 288       |
|    iterations      | 32000     |
|    time_elapsed    | 110       |
|    total_timesteps | 32000     |
----------------------------------
----------------------------------------
| policy_id               | 0          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -971       |
| time/                   |            |
|    fps                  | 323        |
|    iterations           | 64000      |
|    time_elapsed         | 198        |
|    total_timesteps      | 64000      |
| train/                  |            |
|    approx_kl            | 0.00840404 |
|    clip_fraction        | 0.00556    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.19      |
|    explained_variance   | 0.000156   |
|    learning_rate        | 0.0001     |
|    loss                 | 6.91e+03   |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.000678  |
|    value_loss           | 1.4e+04    |
----------------------------------------
Early stopping at step 21 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -959        |
| time/                   |             |
|    fps                  | 310         |
|    iterations           | 64000       |
|    time_elapsed         | 206         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.013424726 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | -0.000169   |
|    learning_rate        | 0.0001      |
|    loss                 | 6.62e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00239    |
|    value_loss           | 1.37e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -877        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 64000       |
|    time_elapsed         | 216         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.014980938 |
|    clip_fraction        | 0.0112      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | -6.26e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 5.15e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 1.07e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -919        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 64000       |
|    time_elapsed         | 226         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.013758428 |
|    clip_fraction        | 0.0118      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | -8.43e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 4.18e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00135    |
|    value_loss           | 8.54e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -930        |
| time/                   |             |
|    fps                  | 270         |
|    iterations           | 64000       |
|    time_elapsed         | 236         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.011289221 |
|    clip_fraction        | 0.0132      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | -0.00014    |
|    learning_rate        | 0.0001      |
|    loss                 | 6.63e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00138    |
|    value_loss           | 1.35e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -926        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 96000       |
|    time_elapsed         | 331         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.015088242 |
|    clip_fraction        | 0.0168      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | -5.35e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 5.06e+03    |
|    n_updates            | 52          |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 1.01e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -899        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 96000       |
|    time_elapsed         | 342         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.012563018 |
|    clip_fraction        | 0.0137      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | -8.82e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 4.69e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00143    |
|    value_loss           | 9.45e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -824        |
| time/                   |             |
|    fps                  | 272         |
|    iterations           | 96000       |
|    time_elapsed         | 352         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.012939816 |
|    clip_fraction        | 0.0151      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 3.19e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 4.8e+03     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00127    |
|    value_loss           | 9.75e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -897        |
| time/                   |             |
|    fps                  | 264         |
|    iterations           | 96000       |
|    time_elapsed         | 363         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.011813069 |
|    clip_fraction        | 0.0105      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 1.16e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 5.93e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00112    |
|    value_loss           | 1.19e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -852        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 96000       |
|    time_elapsed         | 373         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.010570668 |
|    clip_fraction        | 0.0133      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 4.66e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 3.79e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00126    |
|    value_loss           | 7.57e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -822        |
| time/                   |             |
|    fps                  | 271         |
|    iterations           | 128000      |
|    time_elapsed         | 471         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.012667961 |
|    clip_fraction        | 0.015       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | -5.2e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 3.58e+03    |
|    n_updates            | 82          |
|    policy_gradient_loss | -0.00143    |
|    value_loss           | 7.23e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -814        |
| time/                   |             |
|    fps                  | 265         |
|    iterations           | 128000      |
|    time_elapsed         | 481         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.014735851 |
|    clip_fraction        | 0.0135      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | -5.01e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 4.03e+03    |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00141    |
|    value_loss           | 8e+03       |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -777        |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 128000      |
|    time_elapsed         | 491         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.010437388 |
|    clip_fraction        | 0.00801     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | -1.29e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.35e+03    |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.000753   |
|    value_loss           | 6.83e+03    |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -829         |
| time/                   |              |
|    fps                  | 255          |
|    iterations           | 128000       |
|    time_elapsed         | 501          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0125011895 |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | -2.07e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 4.39e+03     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00166     |
|    value_loss           | 8.87e+03     |
------------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -735        |
| time/                   |             |
|    fps                  | 249         |
|    iterations           | 128000      |
|    time_elapsed         | 512         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.008434171 |
|    clip_fraction        | 0.00762     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | -1.34e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.1e+03     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.000718   |
|    value_loss           | 6.12e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -702        |
| time/                   |             |
|    fps                  | 264         |
|    iterations           | 160000      |
|    time_elapsed         | 605         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.012461555 |
|    clip_fraction        | 0.0174      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | -6.93e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.57e+03    |
|    n_updates            | 112         |
|    policy_gradient_loss | -0.00138    |
|    value_loss           | 5.04e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -726        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 160000      |
|    time_elapsed         | 616         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.009772755 |
|    clip_fraction        | 0.0272      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | -7.03e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.11e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00207    |
|    value_loss           | 6.22e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -656        |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 160000      |
|    time_elapsed         | 626         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.013813343 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | -2.35e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.93e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00238    |
|    value_loss           | 5.85e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -694        |
| time/                   |             |
|    fps                  | 251         |
|    iterations           | 160000      |
|    time_elapsed         | 636         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.012253544 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | -7.51e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.67e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00158    |
|    value_loss           | 5.33e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -650        |
| time/                   |             |
|    fps                  | 245         |
|    iterations           | 160000      |
|    time_elapsed         | 651         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.013305118 |
|    clip_fraction        | 0.0301      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | -1.61e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.75e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0024     |
|    value_loss           | 5.55e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -592        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 192000      |
|    time_elapsed         | 738         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.013251668 |
|    clip_fraction        | 0.0149      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | -2.75e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.11e+03    |
|    n_updates            | 142         |
|    policy_gradient_loss | -0.00129    |
|    value_loss           | 4.23e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -646        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 192000      |
|    time_elapsed         | 749         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.011039287 |
|    clip_fraction        | 0.0168      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | -3.46e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.72e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 5.4e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -574        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 192000      |
|    time_elapsed         | 759         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.014359518 |
|    clip_fraction        | 0.0128      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | -2.04e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.84e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00108    |
|    value_loss           | 3.71e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -592        |
| time/                   |             |
|    fps                  | 249         |
|    iterations           | 192000      |
|    time_elapsed         | 770         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.008809353 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | -2.91e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.84e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.000936   |
|    value_loss           | 3.71e+03    |
-----------------------------------------
Early stopping at step 18 due to reaching max kl: 0.02
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -574         |
| time/                   |              |
|    fps                  | 246          |
|    iterations           | 192000       |
|    time_elapsed         | 780          |
|    total_timesteps      | 192000       |
| train/                  |              |
|    approx_kl            | 0.0144067835 |
|    clip_fraction        | 0.0239       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | -2.13e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 1.66e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00211     |
|    value_loss           | 3.31e+03     |
------------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -534        |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 224000      |
|    time_elapsed         | 867         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.013140809 |
|    clip_fraction        | 0.0186      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | -2.91e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.4e+03     |
|    n_updates            | 172         |
|    policy_gradient_loss | -0.00148    |
|    value_loss           | 2.86e+03    |
-----------------------------------------
Early stopping at step 27 due to reaching max kl: 0.02
----------------------------------------
| policy_id               | 1          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -576       |
| time/                   |            |
|    fps                  | 255        |
|    iterations           | 224000     |
|    time_elapsed         | 876        |
|    total_timesteps      | 224000     |
| train/                  |            |
|    approx_kl            | 0.01474116 |
|    clip_fraction        | 0.0192     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.1       |
|    explained_variance   | -5.25e-06  |
|    learning_rate        | 0.0001     |
|    loss                 | 1.92e+03   |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.00173   |
|    value_loss           | 3.87e+03   |
----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -501        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 224000      |
|    time_elapsed         | 887         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.012680611 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | -7.51e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.32e+03    |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00157    |
|    value_loss           | 2.68e+03    |
-----------------------------------------
Early stopping at step 26 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -545        |
| time/                   |             |
|    fps                  | 249         |
|    iterations           | 224000      |
|    time_elapsed         | 897         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.015076574 |
|    clip_fraction        | 0.0314      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | -3.37e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.74e+03    |
|    n_updates            | 169         |
|    policy_gradient_loss | -0.00262    |
|    value_loss           | 3.4e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -517        |
| time/                   |             |
|    fps                  | 246         |
|    iterations           | 224000      |
|    time_elapsed         | 908         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.014133835 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | -1.54e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.21e+03    |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00183    |
|    value_loss           | 2.48e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -471        |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 256000      |
|    time_elapsed         | 994         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.015056973 |
|    clip_fraction        | 0.0263      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | -1.51e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.52e+03    |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00216    |
|    value_loss           | 3.05e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -497        |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 256000      |
|    time_elapsed         | 1005        |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.013223745 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -5.13e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.49e+03    |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00152    |
|    value_loss           | 3.02e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -430        |
| time/                   |             |
|    fps                  | 251         |
|    iterations           | 256000      |
|    time_elapsed         | 1016        |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.015140109 |
|    clip_fraction        | 0.0231      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | -4.17e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.49e+03    |
|    n_updates            | 207         |
|    policy_gradient_loss | -0.00194    |
|    value_loss           | 3.01e+03    |
-----------------------------------------
Early stopping at step 14 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -461        |
| time/                   |             |
|    fps                  | 250         |
|    iterations           | 256000      |
|    time_elapsed         | 1021        |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.008246454 |
|    clip_fraction        | 0.011       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | -1.66e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.82e+03    |
|    n_updates            | 199         |
|    policy_gradient_loss | -0.000963   |
|    value_loss           | 3.67e+03    |
-----------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -453        |
| time/                   |             |
|    fps                  | 248         |
|    iterations           | 256000      |
|    time_elapsed         | 1031        |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.014042236 |
|    clip_fraction        | 0.0226      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | -8.11e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.51e+03    |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00183    |
|    value_loss           | 3.03e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -402        |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 288000      |
|    time_elapsed         | 1112        |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.008576784 |
|    clip_fraction        | 0.00404     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -3.08e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 869         |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.000498   |
|    value_loss           | 1.77e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -424        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 288000      |
|    time_elapsed         | 1123        |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.011128243 |
|    clip_fraction        | 0.0283      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -8.23e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 953         |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00215    |
|    value_loss           | 1.9e+03     |
-----------------------------------------
Early stopping at step 27 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -385        |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 288000      |
|    time_elapsed         | 1134        |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.014955226 |
|    clip_fraction        | 0.0156      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -8.82e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 662         |
|    n_updates            | 222         |
|    policy_gradient_loss | -0.00116    |
|    value_loss           | 1.37e+03    |
-----------------------------------------
Early stopping at step 16 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -399        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 288000      |
|    time_elapsed         | 1140        |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.015171372 |
|    clip_fraction        | 0.0311      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -2.55e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 633         |
|    n_updates            | 225         |
|    policy_gradient_loss | -0.00213    |
|    value_loss           | 1.29e+03    |
-----------------------------------------
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -374         |
| time/                   |              |
|    fps                  | 249          |
|    iterations           | 288000       |
|    time_elapsed         | 1152         |
|    total_timesteps      | 288000       |
| train/                  |              |
|    approx_kl            | 0.0074222763 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -1.35e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 861          |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 1.71e+03     |
------------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -343        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 320000      |
|    time_elapsed         | 1233        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.014301274 |
|    clip_fraction        | 0.0252      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -1.13e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 694         |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00193    |
|    value_loss           | 1.4e+03     |
-----------------------------------------
Early stopping at step 21 due to reaching max kl: 0.02
----------------------------------------
| policy_id               | 1          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -362       |
| time/                   |            |
|    fps                  | 257        |
|    iterations           | 320000     |
|    time_elapsed         | 1241       |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.01514213 |
|    clip_fraction        | 0.0129     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.02      |
|    explained_variance   | -6.79e-06  |
|    learning_rate        | 0.0001     |
|    loss                 | 803        |
|    n_updates            | 268        |
|    policy_gradient_loss | -0.00119   |
|    value_loss           | 1.57e+03   |
----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -310        |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 320000      |
|    time_elapsed         | 1253        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.015398321 |
|    clip_fraction        | 0.029       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -4.89e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 593         |
|    n_updates            | 239         |
|    policy_gradient_loss | -0.00205    |
|    value_loss           | 1.22e+03    |
-----------------------------------------
Early stopping at step 14 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -300        |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 320000      |
|    time_elapsed         | 1258        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.014905813 |
|    clip_fraction        | 0.0137      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | -1.41e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 650         |
|    n_updates            | 255         |
|    policy_gradient_loss | -0.00133    |
|    value_loss           | 1.31e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -322        |
| time/                   |             |
|    fps                  | 251         |
|    iterations           | 320000      |
|    time_elapsed         | 1270        |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.009361396 |
|    clip_fraction        | 0.0218      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | -9.66e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 402         |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00167    |
|    value_loss           | 808         |
-----------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -280        |
| time/                   |             |
|    fps                  | 261         |
|    iterations           | 352000      |
|    time_elapsed         | 1344        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.015009824 |
|    clip_fraction        | 0.0394      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -2.16e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 627         |
|    n_updates            | 282         |
|    policy_gradient_loss | -0.00256    |
|    value_loss           | 1.25e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -313        |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 352000      |
|    time_elapsed         | 1359        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.014800224 |
|    clip_fraction        | 0.0234      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -7.75e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 693         |
|    n_updates            | 298         |
|    policy_gradient_loss | -0.00171    |
|    value_loss           | 1.39e+03    |
-----------------------------------------
Early stopping at step 23 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -270        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 352000      |
|    time_elapsed         | 1371        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.014775965 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -7.39e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 467         |
|    n_updates            | 254         |
|    policy_gradient_loss | -0.00171    |
|    value_loss           | 943         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -264        |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 352000      |
|    time_elapsed         | 1383        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.012489341 |
|    clip_fraction        | 0.02        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -1.25e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 373         |
|    n_updates            | 285         |
|    policy_gradient_loss | -0.00145    |
|    value_loss           | 749         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -269        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 352000      |
|    time_elapsed         | 1394        |
|    total_timesteps      | 352000      |
| train/                  |             |
|    approx_kl            | 0.015073675 |
|    clip_fraction        | 0.0309      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | -1.24e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 644         |
|    n_updates            | 296         |
|    policy_gradient_loss | -0.00225    |
|    value_loss           | 1.32e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 384000      |
|    time_elapsed         | 1463        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.011377771 |
|    clip_fraction        | 0.0205      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -5.25e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 356         |
|    n_updates            | 312         |
|    policy_gradient_loss | -0.0012     |
|    value_loss           | 702         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -264        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 384000      |
|    time_elapsed         | 1478        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.015253253 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -4.05e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 553         |
|    n_updates            | 322         |
|    policy_gradient_loss | -0.00167    |
|    value_loss           | 1.13e+03    |
-----------------------------------------
----------------------------------------
| policy_id               | 2          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -232       |
| time/                   |            |
|    fps                  | 257        |
|    iterations           | 384000     |
|    time_elapsed         | 1493       |
|    total_timesteps      | 384000     |
| train/                  |            |
|    approx_kl            | 0.01075998 |
|    clip_fraction        | 0.0285     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.98      |
|    explained_variance   | -8.94e-06  |
|    learning_rate        | 0.0001     |
|    loss                 | 434        |
|    n_updates            | 284        |
|    policy_gradient_loss | -0.00217   |
|    value_loss           | 878        |
----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -229        |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 384000      |
|    time_elapsed         | 1508        |
|    total_timesteps      | 384000      |
| train/                  |             |
|    approx_kl            | 0.013782405 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | -4.77e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 345         |
|    n_updates            | 315         |
|    policy_gradient_loss | -0.00158    |
|    value_loss           | 680         |
-----------------------------------------
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -233         |
| time/                   |              |
|    fps                  | 252          |
|    iterations           | 384000       |
|    time_elapsed         | 1520         |
|    total_timesteps      | 384000       |
| train/                  |              |
|    approx_kl            | 0.0141915865 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | -5.96e-06    |
|    learning_rate        | 0.0001       |
|    loss                 | 322          |
|    n_updates            | 326          |
|    policy_gradient_loss | -0.00124     |
|    value_loss           | 647          |
------------------------------------------
Early stopping at step 20 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -214        |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 416000      |
|    time_elapsed         | 1584        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.009943205 |
|    clip_fraction        | 0.0103      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0001      |
|    loss                 | 387         |
|    n_updates            | 342         |
|    policy_gradient_loss | -0.000832   |
|    value_loss           | 774         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -215        |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 416000      |
|    time_elapsed         | 1598        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.012799295 |
|    clip_fraction        | 0.0305      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -7.15e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 303         |
|    n_updates            | 352         |
|    policy_gradient_loss | -0.00238    |
|    value_loss           | 611         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -197        |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 416000      |
|    time_elapsed         | 1613        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.009144651 |
|    clip_fraction        | 0.0194      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 1.67e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 312         |
|    n_updates            | 314         |
|    policy_gradient_loss | -0.00121    |
|    value_loss           | 620         |
-----------------------------------------
Early stopping at step 18 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -216        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 416000      |
|    time_elapsed         | 1623        |
|    total_timesteps      | 416000      |
| train/                  |             |
|    approx_kl            | 0.010589329 |
|    clip_fraction        | 0.0254      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -3.58e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 427         |
|    n_updates            | 345         |
|    policy_gradient_loss | -0.00178    |
|    value_loss           | 872         |
-----------------------------------------
----------------------------------------
| policy_id               | 4          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -195       |
| time/                   |            |
|    fps                  | 253        |
|    iterations           | 416000     |
|    time_elapsed         | 1638       |
|    total_timesteps      | 416000     |
| train/                  |            |
|    approx_kl            | 0.01559804 |
|    clip_fraction        | 0.0242     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.06      |
|    explained_variance   | -5.25e-06  |
|    learning_rate        | 0.0001     |
|    loss                 | 259        |
|    n_updates            | 347        |
|    policy_gradient_loss | -0.00183   |
|    value_loss           | 520        |
----------------------------------------
Early stopping at step 16 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -187        |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 448000      |
|    time_elapsed         | 1703        |
|    total_timesteps      | 448000      |
| train/                  |             |
|    approx_kl            | 0.013195836 |
|    clip_fraction        | 0.0193      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | -4.17e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 218         |
|    n_updates            | 372         |
|    policy_gradient_loss | -0.00153    |
|    value_loss           | 441         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -178        |
| time/                   |             |
|    fps                  | 261         |
|    iterations           | 448000      |
|    time_elapsed         | 1714        |
|    total_timesteps      | 448000      |
| train/                  |             |
|    approx_kl            | 0.005055808 |
|    clip_fraction        | 0.00877     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -2.15e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 300         |
|    n_updates            | 382         |
|    policy_gradient_loss | -0.000871   |
|    value_loss           | 603         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -161        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 448000      |
|    time_elapsed         | 1725        |
|    total_timesteps      | 448000      |
| train/                  |             |
|    approx_kl            | 0.014853982 |
|    clip_fraction        | 0.0135      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | -5.6e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 236         |
|    n_updates            | 333         |
|    policy_gradient_loss | -0.0011     |
|    value_loss           | 473         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -187        |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 448000      |
|    time_elapsed         | 1739        |
|    total_timesteps      | 448000      |
| train/                  |             |
|    approx_kl            | 0.013763095 |
|    clip_fraction        | 0.0181      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -2.06e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 258         |
|    n_updates            | 375         |
|    policy_gradient_loss | -0.00145    |
|    value_loss           | 519         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -165        |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 448000      |
|    time_elapsed         | 1755        |
|    total_timesteps      | 448000      |
| train/                  |             |
|    approx_kl            | 0.015023639 |
|    clip_fraction        | 0.0358      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -7.51e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 243         |
|    n_updates            | 364         |
|    policy_gradient_loss | -0.00252    |
|    value_loss           | 480         |
-----------------------------------------
Early stopping at step 29 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -150        |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 480000      |
|    time_elapsed         | 1829        |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.009513406 |
|    clip_fraction        | 0.0503      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -4.84e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 201         |
|    n_updates            | 402         |
|    policy_gradient_loss | -0.0012     |
|    value_loss           | 414         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -152        |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 480000      |
|    time_elapsed         | 1840        |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.009171076 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | -7.87e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 254         |
|    n_updates            | 412         |
|    policy_gradient_loss | -0.00192    |
|    value_loss           | 498         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -145        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 480000      |
|    time_elapsed         | 1851        |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.013393147 |
|    clip_fraction        | 0.0205      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -7.87e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 156         |
|    n_updates            | 363         |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 314         |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -155         |
| time/                   |              |
|    fps                  | 257          |
|    iterations           | 480000       |
|    time_elapsed         | 1863         |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0074517224 |
|    clip_fraction        | 0.0213       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | -1.37e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 209          |
|    n_updates            | 405          |
|    policy_gradient_loss | -0.00187     |
|    value_loss           | 438          |
------------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -150        |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 480000      |
|    time_elapsed         | 1875        |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.015138381 |
|    clip_fraction        | 0.0301      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -2.15e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 211         |
|    n_updates            | 394         |
|    policy_gradient_loss | -0.00212    |
|    value_loss           | 432         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -130        |
| time/                   |             |
|    fps                  | 261         |
|    iterations           | 512000      |
|    time_elapsed         | 1955        |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.009243611 |
|    clip_fraction        | 0.0134      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -0.00317    |
|    learning_rate        | 0.0001      |
|    loss                 | 147         |
|    n_updates            | 432         |
|    policy_gradient_loss | -0.00115    |
|    value_loss           | 290         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -126        |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 512000      |
|    time_elapsed         | 1966        |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.009816207 |
|    clip_fraction        | 0.0254      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | -1.65e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 155         |
|    n_updates            | 442         |
|    policy_gradient_loss | -0.00204    |
|    value_loss           | 308         |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -130         |
| time/                   |              |
|    fps                  | 258          |
|    iterations           | 512000       |
|    time_elapsed         | 1978         |
|    total_timesteps      | 512000       |
| train/                  |              |
|    approx_kl            | 0.0149580315 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | -2.43e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 205          |
|    n_updates            | 393          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 415          |
------------------------------------------
Early stopping at step 28 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 512000      |
|    time_elapsed         | 1988        |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.010938646 |
|    clip_fraction        | 0.0203      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -2.84e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 151         |
|    n_updates            | 435         |
|    policy_gradient_loss | -0.00145    |
|    value_loss           | 312         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -123        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 512000      |
|    time_elapsed         | 1999        |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.004330819 |
|    clip_fraction        | 0.0238      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -2.26e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 179         |
|    n_updates            | 424         |
|    policy_gradient_loss | -0.000664   |
|    value_loss           | 384         |
-----------------------------------------
------------------------------------------
| policy_id               | 0            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -112         |
| time/                   |              |
|    fps                  | 261          |
|    iterations           | 544000       |
|    time_elapsed         | 2080         |
|    total_timesteps      | 544000       |
| train/                  |              |
|    approx_kl            | 0.0060608843 |
|    clip_fraction        | 0.00579      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.00378      |
|    learning_rate        | 0.0001       |
|    loss                 | 145          |
|    n_updates            | 462          |
|    policy_gradient_loss | -0.000475    |
|    value_loss           | 297          |
------------------------------------------
----------------------------------------
| policy_id               | 1          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -108       |
| time/                   |            |
|    fps                  | 260        |
|    iterations           | 544000     |
|    time_elapsed         | 2091       |
|    total_timesteps      | 544000     |
| train/                  |            |
|    approx_kl            | 0.00905361 |
|    clip_fraction        | 0.0208     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.8       |
|    explained_variance   | -1.24e-05  |
|    learning_rate        | 0.0001     |
|    loss                 | 173        |
|    n_updates            | 472        |
|    policy_gradient_loss | -0.00141   |
|    value_loss           | 348        |
----------------------------------------
Early stopping at step 21 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -128        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 544000      |
|    time_elapsed         | 2099        |
|    total_timesteps      | 544000      |
| train/                  |             |
|    approx_kl            | 0.015077077 |
|    clip_fraction        | 0.0221      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -1.79e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 144         |
|    n_updates            | 422         |
|    policy_gradient_loss | -0.00165    |
|    value_loss           | 294         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -110        |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 544000      |
|    time_elapsed         | 2110        |
|    total_timesteps      | 544000      |
| train/                  |             |
|    approx_kl            | 0.009364631 |
|    clip_fraction        | 0.0291      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.00218     |
|    learning_rate        | 0.0001      |
|    loss                 | 130         |
|    n_updates            | 465         |
|    policy_gradient_loss | -0.00219    |
|    value_loss           | 257         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 544000      |
|    time_elapsed         | 2121        |
|    total_timesteps      | 544000      |
| train/                  |             |
|    approx_kl            | 0.009309699 |
|    clip_fraction        | 0.0156      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.00217     |
|    learning_rate        | 0.0001      |
|    loss                 | 113         |
|    n_updates            | 454         |
|    policy_gradient_loss | -0.000917   |
|    value_loss           | 231         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 261         |
|    iterations           | 576000      |
|    time_elapsed         | 2200        |
|    total_timesteps      | 576000      |
| train/                  |             |
|    approx_kl            | 0.010079887 |
|    clip_fraction        | 0.00499     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.000878    |
|    learning_rate        | 0.0001      |
|    loss                 | 111         |
|    n_updates            | 492         |
|    policy_gradient_loss | -0.00043    |
|    value_loss           | 224         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -94.5       |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 576000      |
|    time_elapsed         | 2212        |
|    total_timesteps      | 576000      |
| train/                  |             |
|    approx_kl            | 0.014933323 |
|    clip_fraction        | 0.0235      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -2.46e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 125         |
|    n_updates            | 494         |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 256         |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -112         |
| time/                   |              |
|    fps                  | 259          |
|    iterations           | 576000       |
|    time_elapsed         | 2223         |
|    total_timesteps      | 576000       |
| train/                  |              |
|    approx_kl            | 0.0073716054 |
|    clip_fraction        | 0.0155       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -1.24e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 174          |
|    n_updates            | 452          |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 351          |
------------------------------------------
Early stopping at step 24 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -96.3       |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 576000      |
|    time_elapsed         | 2232        |
|    total_timesteps      | 576000      |
| train/                  |             |
|    approx_kl            | 0.010238575 |
|    clip_fraction        | 0.0159      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -0.00801    |
|    learning_rate        | 0.0001      |
|    loss                 | 100         |
|    n_updates            | 495         |
|    policy_gradient_loss | -0.00108    |
|    value_loss           | 199         |
-----------------------------------------
----------------------------------------
| policy_id               | 4          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -90.1      |
| time/                   |            |
|    fps                  | 256        |
|    iterations           | 576000     |
|    time_elapsed         | 2243       |
|    total_timesteps      | 576000     |
| train/                  |            |
|    approx_kl            | 0.01250973 |
|    clip_fraction        | 0.0368     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.92      |
|    explained_variance   | 0.00828    |
|    learning_rate        | 0.0001     |
|    loss                 | 127        |
|    n_updates            | 484        |
|    policy_gradient_loss | -0.00259   |
|    value_loss           | 253        |
----------------------------------------
----------------------------------------
| policy_id               | 0          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -89.6      |
| time/                   |            |
|    fps                  | 261        |
|    iterations           | 608000     |
|    time_elapsed         | 2323       |
|    total_timesteps      | 608000     |
| train/                  |            |
|    approx_kl            | 0.01141745 |
|    clip_fraction        | 0.0035     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2         |
|    explained_variance   | -0.00183   |
|    learning_rate        | 0.0001     |
|    loss                 | 95.5       |
|    n_updates            | 522        |
|    policy_gradient_loss | -0.00058   |
|    value_loss           | 194        |
----------------------------------------
Early stopping at step 22 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -82.6       |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 608000      |
|    time_elapsed         | 2334        |
|    total_timesteps      | 608000      |
| train/                  |             |
|    approx_kl            | 0.004276477 |
|    clip_fraction        | 0.00821     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 4.29e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 87.6        |
|    n_updates            | 524         |
|    policy_gradient_loss | -0.000291   |
|    value_loss           | 200         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -96.8       |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 608000      |
|    time_elapsed         | 2345        |
|    total_timesteps      | 608000      |
| train/                  |             |
|    approx_kl            | 0.015142441 |
|    clip_fraction        | 0.021       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -2.05e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 127         |
|    n_updates            | 477         |
|    policy_gradient_loss | -0.00181    |
|    value_loss           | 260         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -93         |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 608000      |
|    time_elapsed         | 2356        |
|    total_timesteps      | 608000      |
| train/                  |             |
|    approx_kl            | 0.011237873 |
|    clip_fraction        | 0.0144      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -0.000213   |
|    learning_rate        | 0.0001      |
|    loss                 | 95.7        |
|    n_updates            | 525         |
|    policy_gradient_loss | -0.00126    |
|    value_loss           | 192         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -84.6       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 608000      |
|    time_elapsed         | 2367        |
|    total_timesteps      | 608000      |
| train/                  |             |
|    approx_kl            | 0.012701677 |
|    clip_fraction        | 0.024       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.00723     |
|    learning_rate        | 0.0001      |
|    loss                 | 73.6        |
|    n_updates            | 514         |
|    policy_gradient_loss | -0.00185    |
|    value_loss           | 160         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -70.5       |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 640000      |
|    time_elapsed         | 2442        |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.015078103 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -7.63e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 86.6        |
|    n_updates            | 545         |
|    policy_gradient_loss | -0.0017     |
|    value_loss           | 181         |
-----------------------------------------
------------------------------------------
| policy_id               | 1            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -77.5        |
| time/                   |              |
|    fps                  | 260          |
|    iterations           | 640000       |
|    time_elapsed         | 2457         |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0068230852 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 5.01e-06     |
|    learning_rate        | 0.0001       |
|    loss                 | 77           |
|    n_updates            | 554          |
|    policy_gradient_loss | -0.00146     |
|    value_loss           | 157          |
------------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -76.2       |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 640000      |
|    time_elapsed         | 2472        |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.010087578 |
|    clip_fraction        | 0.0243      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 7.75e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 86.1        |
|    n_updates            | 507         |
|    policy_gradient_loss | 0.000769    |
|    value_loss           | 187         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -87.5       |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 640000      |
|    time_elapsed         | 2483        |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.011504054 |
|    clip_fraction        | 0.0128      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -5.59e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 133         |
|    n_updates            | 555         |
|    policy_gradient_loss | -0.000991   |
|    value_loss           | 266         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -74.1       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 640000      |
|    time_elapsed         | 2494        |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.011240263 |
|    clip_fraction        | 0.017       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.0123      |
|    learning_rate        | 0.0001      |
|    loss                 | 83.8        |
|    n_updates            | 544         |
|    policy_gradient_loss | -0.00124    |
|    value_loss           | 174         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -62.3       |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 672000      |
|    time_elapsed         | 2564        |
|    total_timesteps      | 672000      |
| train/                  |             |
|    approx_kl            | 0.009514763 |
|    clip_fraction        | 0.0339      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -1.63e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 37.6        |
|    n_updates            | 575         |
|    policy_gradient_loss | -0.00148    |
|    value_loss           | 90.9        |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -72.3       |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 672000      |
|    time_elapsed         | 2579        |
|    total_timesteps      | 672000      |
| train/                  |             |
|    approx_kl            | 0.012811763 |
|    clip_fraction        | 0.0226      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.00127     |
|    learning_rate        | 0.0001      |
|    loss                 | 100         |
|    n_updates            | 584         |
|    policy_gradient_loss | -0.00127    |
|    value_loss           | 191         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -70.1       |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 672000      |
|    time_elapsed         | 2594        |
|    total_timesteps      | 672000      |
| train/                  |             |
|    approx_kl            | 0.011586305 |
|    clip_fraction        | 0.0118      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | -0.000182   |
|    learning_rate        | 0.0001      |
|    loss                 | 72.9        |
|    n_updates            | 537         |
|    policy_gradient_loss | -0.00095    |
|    value_loss           | 146         |
-----------------------------------------
---------------------------------------
| policy_id               | 3         |
| rollout/                |           |
|    ep_len_mean          | 1e+03     |
|    ep_rew_mean          | -88       |
| time/                   |           |
|    fps                  | 257       |
|    iterations           | 672000    |
|    time_elapsed         | 2609      |
|    total_timesteps      | 672000    |
| train/                  |           |
|    approx_kl            | 0.0145195 |
|    clip_fraction        | 0.0201    |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.94     |
|    explained_variance   | -1.68e-05 |
|    learning_rate        | 0.0001    |
|    loss                 | 114       |
|    n_updates            | 585       |
|    policy_gradient_loss | -0.00144  |
|    value_loss           | 220       |
---------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -66.2       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 672000      |
|    time_elapsed         | 2622        |
|    total_timesteps      | 672000      |
| train/                  |             |
|    approx_kl            | 0.007449397 |
|    clip_fraction        | 0.00994     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.0116     |
|    learning_rate        | 0.0001      |
|    loss                 | 77.7        |
|    n_updates            | 574         |
|    policy_gradient_loss | -0.000716   |
|    value_loss           | 163         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -50         |
| time/                   |             |
|    fps                  | 261         |
|    iterations           | 704000      |
|    time_elapsed         | 2688        |
|    total_timesteps      | 704000      |
| train/                  |             |
|    approx_kl            | 0.010939257 |
|    clip_fraction        | 0.019       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -2.97e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 64.3        |
|    n_updates            | 605         |
|    policy_gradient_loss | -0.00117    |
|    value_loss           | 131         |
-----------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -60.7       |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 704000      |
|    time_elapsed         | 2702        |
|    total_timesteps      | 704000      |
| train/                  |             |
|    approx_kl            | 0.013443658 |
|    clip_fraction        | 0.0116      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.00756     |
|    learning_rate        | 0.0001      |
|    loss                 | 92.1        |
|    n_updates            | 614         |
|    policy_gradient_loss | -0.000918   |
|    value_loss           | 188         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -75.4       |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 704000      |
|    time_elapsed         | 2717        |
|    total_timesteps      | 704000      |
| train/                  |             |
|    approx_kl            | 0.010268586 |
|    clip_fraction        | 0.0208      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | -0.00834    |
|    learning_rate        | 0.0001      |
|    loss                 | 87.1        |
|    n_updates            | 567         |
|    policy_gradient_loss | -0.00128    |
|    value_loss           | 173         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -73         |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 704000      |
|    time_elapsed         | 2732        |
|    total_timesteps      | 704000      |
| train/                  |             |
|    approx_kl            | 0.015167382 |
|    clip_fraction        | 0.0171      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00357    |
|    learning_rate        | 0.0001      |
|    loss                 | 123         |
|    n_updates            | 611         |
|    policy_gradient_loss | -0.00148    |
|    value_loss           | 253         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -59.8       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 704000      |
|    time_elapsed         | 2747        |
|    total_timesteps      | 704000      |
| train/                  |             |
|    approx_kl            | 0.008801293 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.00438     |
|    learning_rate        | 0.0001      |
|    loss                 | 58.5        |
|    n_updates            | 604         |
|    policy_gradient_loss | -0.00127    |
|    value_loss           | 122         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -56.2       |
| time/                   |             |
|    fps                  | 261         |
|    iterations           | 736000      |
|    time_elapsed         | 2817        |
|    total_timesteps      | 736000      |
| train/                  |             |
|    approx_kl            | 0.014893309 |
|    clip_fraction        | 0.0252      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.000112    |
|    learning_rate        | 0.0001      |
|    loss                 | 61          |
|    n_updates            | 631         |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 123         |
-----------------------------------------
------------------------------------------
| policy_id               | 1            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -56.3        |
| time/                   |              |
|    fps                  | 259          |
|    iterations           | 736000       |
|    time_elapsed         | 2832         |
|    total_timesteps      | 736000       |
| train/                  |              |
|    approx_kl            | 0.0112171415 |
|    clip_fraction        | 0.0129       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.0226       |
|    learning_rate        | 0.0001       |
|    loss                 | 49.1         |
|    n_updates            | 644          |
|    policy_gradient_loss | -0.0007      |
|    value_loss           | 98.2         |
------------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -67         |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 736000      |
|    time_elapsed         | 2846        |
|    total_timesteps      | 736000      |
| train/                  |             |
|    approx_kl            | 0.014438391 |
|    clip_fraction        | 0.0156      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 7.83e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 118         |
|    n_updates            | 597         |
|    policy_gradient_loss | -0.00131    |
|    value_loss           | 236         |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -62.7        |
| time/                   |              |
|    fps                  | 257          |
|    iterations           | 736000       |
|    time_elapsed         | 2859         |
|    total_timesteps      | 736000       |
| train/                  |              |
|    approx_kl            | 0.0088757165 |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.00131      |
|    learning_rate        | 0.0001       |
|    loss                 | 47.1         |
|    n_updates            | 641          |
|    policy_gradient_loss | -0.000954    |
|    value_loss           | 97.5         |
------------------------------------------
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -51.6        |
| time/                   |              |
|    fps                  | 256          |
|    iterations           | 736000       |
|    time_elapsed         | 2874         |
|    total_timesteps      | 736000       |
| train/                  |              |
|    approx_kl            | 0.0072873523 |
|    clip_fraction        | 0.0177       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.79        |
|    explained_variance   | -0.0104      |
|    learning_rate        | 0.0001       |
|    loss                 | 83.8         |
|    n_updates            | 634          |
|    policy_gradient_loss | -0.00106     |
|    value_loss           | 176          |
------------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -52.1       |
| time/                   |             |
|    fps                  | 260         |
|    iterations           | 768000      |
|    time_elapsed         | 2946        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.011851387 |
|    clip_fraction        | 0.0174      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -0.0012     |
|    learning_rate        | 0.0001      |
|    loss                 | 84.8        |
|    n_updates            | 661         |
|    policy_gradient_loss | -0.00144    |
|    value_loss           | 168         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -49.4       |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 768000      |
|    time_elapsed         | 2962        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.010460385 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.000331    |
|    learning_rate        | 0.0001      |
|    loss                 | 62.7        |
|    n_updates            | 674         |
|    policy_gradient_loss | -0.00087    |
|    value_loss           | 122         |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -63.5        |
| time/                   |              |
|    fps                  | 257          |
|    iterations           | 768000       |
|    time_elapsed         | 2977         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 0.0070635313 |
|    clip_fraction        | 0.00957      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.00111      |
|    learning_rate        | 0.0001       |
|    loss                 | 53.9         |
|    n_updates            | 627          |
|    policy_gradient_loss | -0.000328    |
|    value_loss           | 111          |
------------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -41.7       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 768000      |
|    time_elapsed         | 2988        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.014341989 |
|    clip_fraction        | 0.0292      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.0028      |
|    learning_rate        | 0.0001      |
|    loss                 | 60.7        |
|    n_updates            | 671         |
|    policy_gradient_loss | -0.0019     |
|    value_loss           | 122         |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -41.8       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 768000      |
|    time_elapsed         | 3000        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.005795999 |
|    clip_fraction        | 0.0136      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | -0.02       |
|    learning_rate        | 0.0001      |
|    loss                 | 60.3        |
|    n_updates            | 664         |
|    policy_gradient_loss | -0.000965   |
|    value_loss           | 125         |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -50.8       |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 800000      |
|    time_elapsed         | 3077        |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.013871269 |
|    clip_fraction        | 0.0263      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | -0.00104    |
|    learning_rate        | 0.0001      |
|    loss                 | 58.6        |
|    n_updates            | 691         |
|    policy_gradient_loss | -0.00162    |
|    value_loss           | 114         |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -48.1       |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 800000      |
|    time_elapsed         | 3092        |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.011021161 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.0103      |
|    learning_rate        | 0.0001      |
|    loss                 | 76          |
|    n_updates            | 704         |
|    policy_gradient_loss | -0.000915   |
|    value_loss           | 151         |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -49.7       |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 800000      |
|    time_elapsed         | 3107        |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.010717799 |
|    clip_fraction        | 0.0218      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.000145    |
|    learning_rate        | 0.0001      |
|    loss                 | 61.4        |
|    n_updates            | 657         |
|    policy_gradient_loss | -0.00157    |
|    value_loss           | 123         |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -42.3       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 800000      |
|    time_elapsed         | 3118        |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.010055587 |
|    clip_fraction        | 0.0128      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.0157      |
|    learning_rate        | 0.0001      |
|    loss                 | 45.3        |
|    n_updates            | 701         |
|    policy_gradient_loss | -0.00102    |
|    value_loss           | 90.3        |
-----------------------------------------
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -31.3        |
| time/                   |              |
|    fps                  | 255          |
|    iterations           | 800000       |
|    time_elapsed         | 3129         |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0055334726 |
|    clip_fraction        | 0.0153       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.00199     |
|    learning_rate        | 0.0001       |
|    loss                 | 31.7         |
|    n_updates            | 694          |
|    policy_gradient_loss | -0.00065     |
|    value_loss           | 64.7         |
------------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -41.2       |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 832000      |
|    time_elapsed         | 3214        |
|    total_timesteps      | 832000      |
| train/                  |             |
|    approx_kl            | 0.011995319 |
|    clip_fraction        | 0.0221      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -1.17e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 45.7        |
|    n_updates            | 721         |
|    policy_gradient_loss | -0.00149    |
|    value_loss           | 93          |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -37.2       |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 832000      |
|    time_elapsed         | 3230        |
|    total_timesteps      | 832000      |
| train/                  |             |
|    approx_kl            | 0.012859598 |
|    clip_fraction        | 0.0218      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | -0.00791    |
|    learning_rate        | 0.0001      |
|    loss                 | 35.8        |
|    n_updates            | 734         |
|    policy_gradient_loss | -0.00122    |
|    value_loss           | 72          |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -39.3       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 832000      |
|    time_elapsed         | 3241        |
|    total_timesteps      | 832000      |
| train/                  |             |
|    approx_kl            | 0.008501619 |
|    clip_fraction        | 0.00348     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -0.0044     |
|    learning_rate        | 0.0001      |
|    loss                 | 50.2        |
|    n_updates            | 687         |
|    policy_gradient_loss | -0.000459   |
|    value_loss           | 98          |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -33.2       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 832000      |
|    time_elapsed         | 3252        |
|    total_timesteps      | 832000      |
| train/                  |             |
|    approx_kl            | 0.010367859 |
|    clip_fraction        | 0.0296      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.00986    |
|    learning_rate        | 0.0001      |
|    loss                 | 70.2        |
|    n_updates            | 731         |
|    policy_gradient_loss | -0.00212    |
|    value_loss           | 138         |
-----------------------------------------
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -22.4        |
| time/                   |              |
|    fps                  | 254          |
|    iterations           | 832000       |
|    time_elapsed         | 3263         |
|    total_timesteps      | 832000       |
| train/                  |              |
|    approx_kl            | 0.0069018193 |
|    clip_fraction        | 0.0161       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.75        |
|    explained_variance   | -0.00358     |
|    learning_rate        | 0.0001       |
|    loss                 | 38.7         |
|    n_updates            | 724          |
|    policy_gradient_loss | -0.00142     |
|    value_loss           | 74.8         |
------------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -29.6       |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 864000      |
|    time_elapsed         | 3355        |
|    total_timesteps      | 864000      |
| train/                  |             |
|    approx_kl            | 0.010801505 |
|    clip_fraction        | 0.0294      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.000157    |
|    learning_rate        | 0.0001      |
|    loss                 | 42.9        |
|    n_updates            | 751         |
|    policy_gradient_loss | -0.00152    |
|    value_loss           | 83.1        |
-----------------------------------------
------------------------------------------
| policy_id               | 1            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -25.4        |
| time/                   |              |
|    fps                  | 256          |
|    iterations           | 864000       |
|    time_elapsed         | 3370         |
|    total_timesteps      | 864000       |
| train/                  |              |
|    approx_kl            | 0.0070256563 |
|    clip_fraction        | 0.0132       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.00404      |
|    learning_rate        | 0.0001       |
|    loss                 | 24.4         |
|    n_updates            | 764          |
|    policy_gradient_loss | -0.000983    |
|    value_loss           | 50.8         |
------------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -34.3        |
| time/                   |              |
|    fps                  | 255          |
|    iterations           | 864000       |
|    time_elapsed         | 3382         |
|    total_timesteps      | 864000       |
| train/                  |              |
|    approx_kl            | 0.0073835053 |
|    clip_fraction        | 0.00759      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.89        |
|    explained_variance   | -0.000419    |
|    learning_rate        | 0.0001       |
|    loss                 | 20           |
|    n_updates            | 717          |
|    policy_gradient_loss | -0.0005      |
|    value_loss           | 42.7         |
------------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -31.1       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 864000      |
|    time_elapsed         | 3392        |
|    total_timesteps      | 864000      |
| train/                  |             |
|    approx_kl            | 0.012631824 |
|    clip_fraction        | 0.0247      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -0.0165     |
|    learning_rate        | 0.0001      |
|    loss                 | 32.3        |
|    n_updates            | 761         |
|    policy_gradient_loss | -0.00105    |
|    value_loss           | 62.5        |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -17.8       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 864000      |
|    time_elapsed         | 3401        |
|    total_timesteps      | 864000      |
| train/                  |             |
|    approx_kl            | 0.005651346 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.0283      |
|    learning_rate        | 0.0001      |
|    loss                 | 30.6        |
|    n_updates            | 754         |
|    policy_gradient_loss | -0.00116    |
|    value_loss           | 60.8        |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -24.7       |
| time/                   |             |
|    fps                  | 256         |
|    iterations           | 896000      |
|    time_elapsed         | 3496        |
|    total_timesteps      | 896000      |
| train/                  |             |
|    approx_kl            | 0.011200979 |
|    clip_fraction        | 0.0354      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.00406     |
|    learning_rate        | 0.0001      |
|    loss                 | 20.2        |
|    n_updates            | 781         |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 40.4        |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -23.9       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 896000      |
|    time_elapsed         | 3509        |
|    total_timesteps      | 896000      |
| train/                  |             |
|    approx_kl            | 0.009318231 |
|    clip_fraction        | 0.0222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.0141      |
|    learning_rate        | 0.0001      |
|    loss                 | 32.1        |
|    n_updates            | 794         |
|    policy_gradient_loss | -0.00139    |
|    value_loss           | 65.3        |
-----------------------------------------
----------------------------------------
| policy_id               | 2          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -24.3      |
| time/                   |            |
|    fps                  | 254        |
|    iterations           | 896000     |
|    time_elapsed         | 3519       |
|    total_timesteps      | 896000     |
| train/                  |            |
|    approx_kl            | 0.01155335 |
|    clip_fraction        | 0.0335     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.91      |
|    explained_variance   | 9.85e-05   |
|    learning_rate        | 0.0001     |
|    loss                 | 42.3       |
|    n_updates            | 747        |
|    policy_gradient_loss | -0.0018    |
|    value_loss           | 84.7       |
----------------------------------------
---------------------------------------
| policy_id               | 3         |
| rollout/                |           |
|    ep_len_mean          | 1e+03     |
|    ep_rew_mean          | -21.1     |
| time/                   |           |
|    fps                  | 253       |
|    iterations           | 896000    |
|    time_elapsed         | 3530      |
|    total_timesteps      | 896000    |
| train/                  |           |
|    approx_kl            | 0.0101293 |
|    clip_fraction        | 0.0129    |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.89     |
|    explained_variance   | -0.00327  |
|    learning_rate        | 0.0001    |
|    loss                 | 27.6      |
|    n_updates            | 791       |
|    policy_gradient_loss | -0.000787 |
|    value_loss           | 55.6      |
---------------------------------------
------------------------------------------
| policy_id               | 4            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -10          |
| time/                   |              |
|    fps                  | 253          |
|    iterations           | 896000       |
|    time_elapsed         | 3540         |
|    total_timesteps      | 896000       |
| train/                  |              |
|    approx_kl            | 0.0076959087 |
|    clip_fraction        | 0.031        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -0.0187      |
|    learning_rate        | 0.0001       |
|    loss                 | 18.9         |
|    n_updates            | 784          |
|    policy_gradient_loss | -0.00178     |
|    value_loss           | 38           |
------------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -20.8       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 928000      |
|    time_elapsed         | 3631        |
|    total_timesteps      | 928000      |
| train/                  |             |
|    approx_kl            | 0.012302988 |
|    clip_fraction        | 0.014       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.000775    |
|    learning_rate        | 0.0001      |
|    loss                 | 27.5        |
|    n_updates            | 811         |
|    policy_gradient_loss | -0.00104    |
|    value_loss           | 53.2        |
-----------------------------------------
------------------------------------------
| policy_id               | 1            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -24.7        |
| time/                   |              |
|    fps                  | 254          |
|    iterations           | 928000       |
|    time_elapsed         | 3642         |
|    total_timesteps      | 928000       |
| train/                  |              |
|    approx_kl            | 0.0101205995 |
|    clip_fraction        | 0.0182       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.49        |
|    explained_variance   | -0.00364     |
|    learning_rate        | 0.0001       |
|    loss                 | 28.2         |
|    n_updates            | 824          |
|    policy_gradient_loss | -0.00135     |
|    value_loss           | 56.9         |
------------------------------------------
----------------------------------------
| policy_id               | 2          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -21.5      |
| time/                   |            |
|    fps                  | 254        |
|    iterations           | 928000     |
|    time_elapsed         | 3653       |
|    total_timesteps      | 928000     |
| train/                  |            |
|    approx_kl            | 0.01045179 |
|    clip_fraction        | 0.0355     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.92      |
|    explained_variance   | 0.00101    |
|    learning_rate        | 0.0001     |
|    loss                 | 14.5       |
|    n_updates            | 777        |
|    policy_gradient_loss | -0.00119   |
|    value_loss           | 31.7       |
----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -19.2       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 928000      |
|    time_elapsed         | 3663        |
|    total_timesteps      | 928000      |
| train/                  |             |
|    approx_kl            | 0.014032245 |
|    clip_fraction        | 0.0585      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.0038      |
|    learning_rate        | 0.0001      |
|    loss                 | 25          |
|    n_updates            | 821         |
|    policy_gradient_loss | -0.00246    |
|    value_loss           | 50.8        |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -8.23       |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 928000      |
|    time_elapsed         | 3673        |
|    total_timesteps      | 928000      |
| train/                  |             |
|    approx_kl            | 0.013096587 |
|    clip_fraction        | 0.037       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.0236      |
|    learning_rate        | 0.0001      |
|    loss                 | 15.3        |
|    n_updates            | 814         |
|    policy_gradient_loss | -0.00202    |
|    value_loss           | 30.2        |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -19.5       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 960000      |
|    time_elapsed         | 3760        |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.007985616 |
|    clip_fraction        | 0.0211      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00151    |
|    learning_rate        | 0.0001      |
|    loss                 | 32.8        |
|    n_updates            | 841         |
|    policy_gradient_loss | -0.00105    |
|    value_loss           | 66.3        |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -19.9       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 960000      |
|    time_elapsed         | 3771        |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.008361623 |
|    clip_fraction        | 0.0274      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.00741     |
|    learning_rate        | 0.0001      |
|    loss                 | 34.9        |
|    n_updates            | 854         |
|    policy_gradient_loss | -0.00138    |
|    value_loss           | 69.3        |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -14.3       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 960000      |
|    time_elapsed         | 3783        |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.010118552 |
|    clip_fraction        | 0.0327      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 9.07e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 29.2        |
|    n_updates            | 807         |
|    policy_gradient_loss | -0.00115    |
|    value_loss           | 57.9        |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -16.9       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 960000      |
|    time_elapsed         | 3793        |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.008832322 |
|    clip_fraction        | 0.0157      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.0174      |
|    learning_rate        | 0.0001      |
|    loss                 | 22.9        |
|    n_updates            | 851         |
|    policy_gradient_loss | -0.000822   |
|    value_loss           | 50.7        |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -5.7        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 960000      |
|    time_elapsed         | 3803        |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.007953198 |
|    clip_fraction        | 0.02        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.0169      |
|    learning_rate        | 0.0001      |
|    loss                 | 29.8        |
|    n_updates            | 844         |
|    policy_gradient_loss | -0.00135    |
|    value_loss           | 66.7        |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -12.8       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 992000      |
|    time_elapsed         | 3887        |
|    total_timesteps      | 992000      |
| train/                  |             |
|    approx_kl            | 0.010087615 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0075     |
|    learning_rate        | 0.0001      |
|    loss                 | 16.4        |
|    n_updates            | 871         |
|    policy_gradient_loss | -0.00146    |
|    value_loss           | 34          |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -14.5       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 992000      |
|    time_elapsed         | 3898        |
|    total_timesteps      | 992000      |
| train/                  |             |
|    approx_kl            | 0.009532347 |
|    clip_fraction        | 0.0296      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.012       |
|    learning_rate        | 0.0001      |
|    loss                 | 18.6        |
|    n_updates            | 884         |
|    policy_gradient_loss | -0.001      |
|    value_loss           | 36.8        |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -8.36       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 992000      |
|    time_elapsed         | 3909        |
|    total_timesteps      | 992000      |
| train/                  |             |
|    approx_kl            | 0.011583941 |
|    clip_fraction        | 0.0215      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.0056      |
|    learning_rate        | 0.0001      |
|    loss                 | 7.42        |
|    n_updates            | 837         |
|    policy_gradient_loss | -0.00112    |
|    value_loss           | 15.9        |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -13.1        |
| time/                   |              |
|    fps                  | 252          |
|    iterations           | 992000       |
|    time_elapsed         | 3921         |
|    total_timesteps      | 992000       |
| train/                  |              |
|    approx_kl            | 0.0084622465 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.72        |
|    explained_variance   | -0.0258      |
|    learning_rate        | 0.0001       |
|    loss                 | 19.3         |
|    n_updates            | 881          |
|    policy_gradient_loss | -0.000899    |
|    value_loss           | 40.6         |
------------------------------------------
Early stopping at step 10 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -4.73       |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 992000      |
|    time_elapsed         | 3925        |
|    total_timesteps      | 992000      |
| train/                  |             |
|    approx_kl            | 0.004412049 |
|    clip_fraction        | 0.0097      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.0178      |
|    learning_rate        | 0.0001      |
|    loss                 | 14.3        |
|    n_updates            | 874         |
|    policy_gradient_loss | -0.000737   |
|    value_loss           | 29.4        |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -7.79       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 1024000     |
|    time_elapsed         | 4005        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.011747716 |
|    clip_fraction        | 0.04        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.00441    |
|    learning_rate        | 0.0001      |
|    loss                 | 5.63        |
|    n_updates            | 901         |
|    policy_gradient_loss | -0.00144    |
|    value_loss           | 12          |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -10.5       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1024000     |
|    time_elapsed         | 4016        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.009274529 |
|    clip_fraction        | 0.0416      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.68       |
|    explained_variance   | -0.000643   |
|    learning_rate        | 0.0001      |
|    loss                 | 9.79        |
|    n_updates            | 914         |
|    policy_gradient_loss | -0.00118    |
|    value_loss           | 20.3        |
-----------------------------------------
------------------------------------------
| policy_id               | 2            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -8.28        |
| time/                   |              |
|    fps                  | 254          |
|    iterations           | 1024000      |
|    time_elapsed         | 4027         |
|    total_timesteps      | 1024000      |
| train/                  |              |
|    approx_kl            | 0.0116969105 |
|    clip_fraction        | 0.0461       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -7.15e-07    |
|    learning_rate        | 0.0001       |
|    loss                 | 6.7          |
|    n_updates            | 867          |
|    policy_gradient_loss | -0.00144     |
|    value_loss           | 15.4         |
------------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -9.86       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 1024000     |
|    time_elapsed         | 4038        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.015272384 |
|    clip_fraction        | 0.0427      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.0198      |
|    learning_rate        | 0.0001      |
|    loss                 | 15.9        |
|    n_updates            | 892         |
|    policy_gradient_loss | -0.00124    |
|    value_loss           | 31.7        |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -3.32       |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 1024000     |
|    time_elapsed         | 4050        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.008240217 |
|    clip_fraction        | 0.0121      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | 0.0186      |
|    learning_rate        | 0.0001      |
|    loss                 | 12.2        |
|    n_updates            | 904         |
|    policy_gradient_loss | -0.000648   |
|    value_loss           | 25.5        |
-----------------------------------------
------------------------------------------
| policy_id               | 0            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -5.01        |
| time/                   |              |
|    fps                  | 255          |
|    iterations           | 1056000      |
|    time_elapsed         | 4132         |
|    total_timesteps      | 1056000      |
| train/                  |              |
|    approx_kl            | 0.0115520535 |
|    clip_fraction        | 0.0436       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | -0.00282     |
|    learning_rate        | 0.0001       |
|    loss                 | 9.17         |
|    n_updates            | 931          |
|    policy_gradient_loss | -0.00171     |
|    value_loss           | 19.4         |
------------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -8.76       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1056000     |
|    time_elapsed         | 4142        |
|    total_timesteps      | 1056000     |
| train/                  |             |
|    approx_kl            | 0.008333238 |
|    clip_fraction        | 0.0301      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.00761     |
|    learning_rate        | 0.0001      |
|    loss                 | 21.1        |
|    n_updates            | 944         |
|    policy_gradient_loss | -0.00128    |
|    value_loss           | 42.7        |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -8.75       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1056000     |
|    time_elapsed         | 4152        |
|    total_timesteps      | 1056000     |
| train/                  |             |
|    approx_kl            | 0.013642075 |
|    clip_fraction        | 0.0248      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.000399    |
|    learning_rate        | 0.0001      |
|    loss                 | 20.4        |
|    n_updates            | 897         |
|    policy_gradient_loss | -0.00158    |
|    value_loss           | 42.2        |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -7.62        |
| time/                   |              |
|    fps                  | 253          |
|    iterations           | 1056000      |
|    time_elapsed         | 4163         |
|    total_timesteps      | 1056000      |
| train/                  |              |
|    approx_kl            | 0.0134453215 |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.00361      |
|    learning_rate        | 0.0001       |
|    loss                 | 13.6         |
|    n_updates            | 922          |
|    policy_gradient_loss | -0.00133     |
|    value_loss           | 29.4         |
------------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 0.68        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 1056000     |
|    time_elapsed         | 4175        |
|    total_timesteps      | 1056000     |
| train/                  |             |
|    approx_kl            | 0.006856351 |
|    clip_fraction        | 0.0271      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | -0.0117     |
|    learning_rate        | 0.0001      |
|    loss                 | 13.1        |
|    n_updates            | 934         |
|    policy_gradient_loss | -0.00131    |
|    value_loss           | 26          |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -6.05       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 1088000     |
|    time_elapsed         | 4259        |
|    total_timesteps      | 1088000     |
| train/                  |             |
|    approx_kl            | 0.008976284 |
|    clip_fraction        | 0.0176      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00643    |
|    learning_rate        | 0.0001      |
|    loss                 | 6.93        |
|    n_updates            | 961         |
|    policy_gradient_loss | -0.0011     |
|    value_loss           | 14.7        |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -7.66       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1088000     |
|    time_elapsed         | 4270        |
|    total_timesteps      | 1088000     |
| train/                  |             |
|    approx_kl            | 0.009895405 |
|    clip_fraction        | 0.0507      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.0102      |
|    learning_rate        | 0.0001      |
|    loss                 | 10.5        |
|    n_updates            | 974         |
|    policy_gradient_loss | -0.00149    |
|    value_loss           | 21.4        |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -6.49       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1088000     |
|    time_elapsed         | 4280        |
|    total_timesteps      | 1088000     |
| train/                  |             |
|    approx_kl            | 0.014804723 |
|    clip_fraction        | 0.0569      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.00414     |
|    learning_rate        | 0.0001      |
|    loss                 | 8.87        |
|    n_updates            | 927         |
|    policy_gradient_loss | -0.00181    |
|    value_loss           | 17.8        |
-----------------------------------------
----------------------------------------
| policy_id               | 3          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -6.86      |
| time/                   |            |
|    fps                  | 253        |
|    iterations           | 1088000    |
|    time_elapsed         | 4290       |
|    total_timesteps      | 1088000    |
| train/                  |            |
|    approx_kl            | 0.01052014 |
|    clip_fraction        | 0.0183     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.71      |
|    explained_variance   | 0.00173    |
|    learning_rate        | 0.0001     |
|    loss                 | 13.8       |
|    n_updates            | 952        |
|    policy_gradient_loss | -0.00126   |
|    value_loss           | 28.2       |
----------------------------------------
Early stopping at step 25 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 0.42        |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 1088000     |
|    time_elapsed         | 4300        |
|    total_timesteps      | 1088000     |
| train/                  |             |
|    approx_kl            | 0.010373641 |
|    clip_fraction        | 0.0148      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.117       |
|    learning_rate        | 0.0001      |
|    loss                 | 1.08        |
|    n_updates            | 964         |
|    policy_gradient_loss | -0.00116    |
|    value_loss           | 2.19        |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -6.12       |
| time/                   |             |
|    fps                  | 255         |
|    iterations           | 1120000     |
|    time_elapsed         | 4385        |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.010896284 |
|    clip_fraction        | 0.0365      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.000609    |
|    learning_rate        | 0.0001      |
|    loss                 | 18          |
|    n_updates            | 991         |
|    policy_gradient_loss | -0.00132    |
|    value_loss           | 36.5        |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -3.74       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1120000     |
|    time_elapsed         | 4397        |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.010194859 |
|    clip_fraction        | 0.0745      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.00187     |
|    learning_rate        | 0.0001      |
|    loss                 | 6.45        |
|    n_updates            | 1004        |
|    policy_gradient_loss | -0.00188    |
|    value_loss           | 12.7        |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 1120000     |
|    time_elapsed         | 4407        |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.008455932 |
|    clip_fraction        | 0.0371      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.00181     |
|    learning_rate        | 0.0001      |
|    loss                 | 3.76        |
|    n_updates            | 957         |
|    policy_gradient_loss | -0.000982   |
|    value_loss           | 8.11        |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -7.27       |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 1120000     |
|    time_elapsed         | 4418        |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.015051512 |
|    clip_fraction        | 0.0287      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.000541    |
|    learning_rate        | 0.0001      |
|    loss                 | 16.8        |
|    n_updates            | 978         |
|    policy_gradient_loss | -0.00117    |
|    value_loss           | 33          |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -0.36       |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 1120000     |
|    time_elapsed         | 4429        |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.013188965 |
|    clip_fraction        | 0.0196      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.0129      |
|    learning_rate        | 0.0001      |
|    loss                 | 15.3        |
|    n_updates            | 994         |
|    policy_gradient_loss | -0.00102    |
|    value_loss           | 30.9        |
-----------------------------------------
