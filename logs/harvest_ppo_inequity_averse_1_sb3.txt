nohup: ignoring input
/raid/notebook/enhupgu/Marl/marl/lib/python3.8/site-packages/ale_py/roms/__init__.py:84: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management
  __all__ = _resolve_roms()
Using cuda:3 device
Using cuda:3 device
Using cuda:3 device
Using cuda:3 device
Using cuda:3 device
start training 2025-04-16 15:48:28.059840
Arguments successfully written to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3/config.yaml
Logging to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3_1
Logging to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3_1/policy_1
Logging to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3_1/policy_2
Logging to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3_1/policy_3
Logging to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3_1/policy_4
Logging to ./results/sb3/ppo_independent/harvest_ppo_inequity_averse_1_sb3_1/policy_5
----------------------------------
| policy_id          | 0         |
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -1.35e+03 |
| time/              |           |
|    fps             | 494       |
|    iterations      | 32000     |
|    time_elapsed    | 64        |
|    total_timesteps | 32000     |
----------------------------------
---------------------------------
| policy_id          | 1        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -737     |
| time/              |          |
|    fps             | 424      |
|    iterations      | 32000    |
|    time_elapsed    | 75       |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| policy_id          | 2        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -770     |
| time/              |          |
|    fps             | 375      |
|    iterations      | 32000    |
|    time_elapsed    | 85       |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| policy_id          | 3        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -721     |
| time/              |          |
|    fps             | 336      |
|    iterations      | 32000    |
|    time_elapsed    | 95       |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| policy_id          | 4        |
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -765     |
| time/              |          |
|    fps             | 303      |
|    iterations      | 32000    |
|    time_elapsed    | 105      |
|    total_timesteps | 32000    |
---------------------------------
------------------------------------------
| policy_id               | 0            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.21e+03    |
| time/                   |              |
|    fps                  | 359          |
|    iterations           | 64000        |
|    time_elapsed         | 178          |
|    total_timesteps      | 64000        |
| train/                  |              |
|    approx_kl            | 0.0066976547 |
|    clip_fraction        | 0.0121       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.000565     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.52e+04     |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 3.03e+04     |
------------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -739        |
| time/                   |             |
|    fps                  | 339         |
|    iterations           | 64000       |
|    time_elapsed         | 188         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.009461201 |
|    clip_fraction        | 0.00724     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | -0.000101   |
|    learning_rate        | 0.0001      |
|    loss                 | 4.21e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.000822   |
|    value_loss           | 8.54e+03    |
-----------------------------------------
Early stopping at step 27 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -678        |
| time/                   |             |
|    fps                  | 322         |
|    iterations           | 64000       |
|    time_elapsed         | 198         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.014495658 |
|    clip_fraction        | 0.0176      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.000114    |
|    learning_rate        | 0.0001      |
|    loss                 | 4.82e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00166    |
|    value_loss           | 9.76e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -699        |
| time/                   |             |
|    fps                  | 307         |
|    iterations           | 64000       |
|    time_elapsed         | 208         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.013113862 |
|    clip_fraction        | 0.0122      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.00038     |
|    learning_rate        | 0.0001      |
|    loss                 | 3.94e+03    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00141    |
|    value_loss           | 8.09e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -766        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 64000       |
|    time_elapsed         | 218         |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.012045566 |
|    clip_fraction        | 0.0122      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.000231    |
|    learning_rate        | 0.0001      |
|    loss                 | 4.8e+03     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00117    |
|    value_loss           | 9.77e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.09e+03   |
| time/                   |             |
|    fps                  | 329         |
|    iterations           | 96000       |
|    time_elapsed         | 291         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.014635203 |
|    clip_fraction        | 0.0152      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -3.96e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 8.61e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00143    |
|    value_loss           | 1.76e+04    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -689        |
| time/                   |             |
|    fps                  | 318         |
|    iterations           | 96000       |
|    time_elapsed         | 301         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.015052151 |
|    clip_fraction        | 0.0278      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | -1.57e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 4.41e+03    |
|    n_updates            | 58          |
|    policy_gradient_loss | -0.00213    |
|    value_loss           | 8.8e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -655        |
| time/                   |             |
|    fps                  | 308         |
|    iterations           | 96000       |
|    time_elapsed         | 311         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.009789489 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -6.43e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.85e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00157    |
|    value_loss           | 5.75e+03    |
-----------------------------------------
------------------------------------------
| policy_id               | 3            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -661         |
| time/                   |              |
|    fps                  | 298          |
|    iterations           | 96000        |
|    time_elapsed         | 322          |
|    total_timesteps      | 96000        |
| train/                  |              |
|    approx_kl            | 0.0071552405 |
|    clip_fraction        | 0.00787      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | -2.49e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 3.7e+03      |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.000589    |
|    value_loss           | 7.52e+03     |
------------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -708        |
| time/                   |             |
|    fps                  | 288         |
|    iterations           | 96000       |
|    time_elapsed         | 332         |
|    total_timesteps      | 96000       |
| train/                  |             |
|    approx_kl            | 0.013477601 |
|    clip_fraction        | 0.0138      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -8.29e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 4.54e+03    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0013     |
|    value_loss           | 9.13e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -861        |
| time/                   |             |
|    fps                  | 317         |
|    iterations           | 128000      |
|    time_elapsed         | 403         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.013538378 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -4.17e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 5.63e+03    |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00173    |
|    value_loss           | 1.13e+04    |
-----------------------------------------
Early stopping at step 22 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -609        |
| time/                   |             |
|    fps                  | 311         |
|    iterations           | 128000      |
|    time_elapsed         | 410         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.009648906 |
|    clip_fraction        | 0.0246      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | -2.11e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.87e+03    |
|    n_updates            | 88          |
|    policy_gradient_loss | -0.00187    |
|    value_loss           | 5.81e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -519        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 128000      |
|    time_elapsed         | 420         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.010504099 |
|    clip_fraction        | 0.00547     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | -1.08e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.11e+03    |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.000604   |
|    value_loss           | 6.22e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -542        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 128000      |
|    time_elapsed         | 430         |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.010305399 |
|    clip_fraction        | 0.0137      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | -1.55e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.56e+03    |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00115    |
|    value_loss           | 5.03e+03    |
-----------------------------------------
Early stopping at step 26 due to reaching max kl: 0.02
----------------------------------------
| policy_id               | 4          |
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -594       |
| time/                   |            |
|    fps                  | 291        |
|    iterations           | 128000     |
|    time_elapsed         | 438        |
|    total_timesteps      | 128000     |
| train/                  |            |
|    approx_kl            | 0.01383316 |
|    clip_fraction        | 0.00576    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.05      |
|    explained_variance   | -1.13e-05  |
|    learning_rate        | 0.0001     |
|    loss                 | 3.48e+03   |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0008    |
|    value_loss           | 7.02e+03   |
----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -713        |
| time/                   |             |
|    fps                  | 315         |
|    iterations           | 160000      |
|    time_elapsed         | 507         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.015168486 |
|    clip_fraction        | 0.0215      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | -7.99e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 3.08e+03    |
|    n_updates            | 113         |
|    policy_gradient_loss | -0.00181    |
|    value_loss           | 6.15e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -515        |
| time/                   |             |
|    fps                  | 309         |
|    iterations           | 160000      |
|    time_elapsed         | 516         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.014379449 |
|    clip_fraction        | 0.0219      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 2.38e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 2.07e+03    |
|    n_updates            | 118         |
|    policy_gradient_loss | -0.0018     |
|    value_loss           | 4.09e+03    |
-----------------------------------------
Early stopping at step 17 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -459        |
| time/                   |             |
|    fps                  | 305         |
|    iterations           | 160000      |
|    time_elapsed         | 522         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.012282585 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -1.92e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.34e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00173    |
|    value_loss           | 2.8e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -450        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 160000      |
|    time_elapsed         | 532         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.015102044 |
|    clip_fraction        | 0.0264      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -2.1e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 1.1e+03     |
|    n_updates            | 117         |
|    policy_gradient_loss | -0.00192    |
|    value_loss           | 2.29e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -464        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 160000      |
|    time_elapsed         | 542         |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.010616717 |
|    clip_fraction        | 0.00861     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | -2e-05      |
|    learning_rate        | 0.0001      |
|    loss                 | 1.3e+03     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.000796   |
|    value_loss           | 2.6e+03     |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -600        |
| time/                   |             |
|    fps                  | 314         |
|    iterations           | 192000      |
|    time_elapsed         | 609         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.009880388 |
|    clip_fraction        | 0.0161      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 4.29e-06    |
|    learning_rate        | 0.0001      |
|    loss                 | 3.84e+03    |
|    n_updates            | 143         |
|    policy_gradient_loss | -0.00129    |
|    value_loss           | 7.59e+03    |
-----------------------------------------
------------------------------------------
| policy_id               | 1            |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -410         |
| time/                   |              |
|    fps                  | 309          |
|    iterations           | 192000       |
|    time_elapsed         | 619          |
|    total_timesteps      | 192000       |
| train/                  |              |
|    approx_kl            | 0.0152440285 |
|    clip_fraction        | 0.0173       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 3.4e-06      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.14e+03     |
|    n_updates            | 136          |
|    policy_gradient_loss | -0.00151     |
|    value_loss           | 2.25e+03     |
------------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -354        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 192000      |
|    time_elapsed         | 629         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.008366018 |
|    clip_fraction        | 0.0113      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -5.72e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.36e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00101    |
|    value_loss           | 2.79e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -347        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 192000      |
|    time_elapsed         | 639         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.010887868 |
|    clip_fraction        | 0.0112      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -2.44e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.05e+03    |
|    n_updates            | 147         |
|    policy_gradient_loss | -0.00084    |
|    value_loss           | 2.04e+03    |
-----------------------------------------
Early stopping at step 23 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -395        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 192000      |
|    time_elapsed         | 647         |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.009082923 |
|    clip_fraction        | 0.0178      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | -4.05e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.52e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00136    |
|    value_loss           | 3.01e+03    |
-----------------------------------------
Early stopping at step 29 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -536        |
| time/                   |             |
|    fps                  | 314         |
|    iterations           | 224000      |
|    time_elapsed         | 711         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.013958881 |
|    clip_fraction        | 0.0103      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | -1.08e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 2.3e+03     |
|    n_updates            | 173         |
|    policy_gradient_loss | -0.000995   |
|    value_loss           | 4.58e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -349        |
| time/                   |             |
|    fps                  | 310         |
|    iterations           | 224000      |
|    time_elapsed         | 721         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.013395758 |
|    clip_fraction        | 0.0243      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | -6.79e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 992         |
|    n_updates            | 166         |
|    policy_gradient_loss | -0.00169    |
|    value_loss           | 2.04e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -299        |
| time/                   |             |
|    fps                  | 306         |
|    iterations           | 224000      |
|    time_elapsed         | 731         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.012902502 |
|    clip_fraction        | 0.0349      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -1.18e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 690         |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00238    |
|    value_loss           | 1.41e+03    |
-----------------------------------------
Early stopping at step 27 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -307        |
| time/                   |             |
|    fps                  | 302         |
|    iterations           | 224000      |
|    time_elapsed         | 740         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.015175622 |
|    clip_fraction        | 0.019       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -2.31e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 810         |
|    n_updates            | 171         |
|    policy_gradient_loss | -0.00145    |
|    value_loss           | 1.61e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -348        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 224000      |
|    time_elapsed         | 750         |
|    total_timesteps      | 224000      |
| train/                  |             |
|    approx_kl            | 0.015087197 |
|    clip_fraction        | 0.0252      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -1.1e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 1.39e+03    |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00203    |
|    value_loss           | 2.73e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -443        |
| time/                   |             |
|    fps                  | 313         |
|    iterations           | 256000      |
|    time_elapsed         | 815         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.014114802 |
|    clip_fraction        | 0.0168      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -4.29e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.71e+03    |
|    n_updates            | 203         |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 3.48e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -299        |
| time/                   |             |
|    fps                  | 310         |
|    iterations           | 256000      |
|    time_elapsed         | 825         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.009791913 |
|    clip_fraction        | 0.0162      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -1.67e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 960         |
|    n_updates            | 196         |
|    policy_gradient_loss | -0.00144    |
|    value_loss           | 1.91e+03    |
-----------------------------------------
Early stopping at step 22 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 307         |
|    iterations           | 256000      |
|    time_elapsed         | 832         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.015298969 |
|    clip_fraction        | 0.0126      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -1.2e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 627         |
|    n_updates            | 208         |
|    policy_gradient_loss | -0.00122    |
|    value_loss           | 1.27e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -276        |
| time/                   |             |
|    fps                  | 303         |
|    iterations           | 256000      |
|    time_elapsed         | 842         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.010037055 |
|    clip_fraction        | 0.0378      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | -2.74e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 863         |
|    n_updates            | 201         |
|    policy_gradient_loss | -0.00261    |
|    value_loss           | 1.77e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 4           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -287        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 256000      |
|    time_elapsed         | 852         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.014890722 |
|    clip_fraction        | 0.0122      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -1.32e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 924         |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.000897   |
|    value_loss           | 1.87e+03    |
-----------------------------------------
Early stopping at step 13 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 0           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -387        |
| time/                   |             |
|    fps                  | 315         |
|    iterations           | 288000      |
|    time_elapsed         | 914         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.014106614 |
|    clip_fraction        | 0.0215      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | -6.32e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 1.34e+03    |
|    n_updates            | 233         |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 2.71e+03    |
-----------------------------------------
Early stopping at step 20 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 1           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -282        |
| time/                   |             |
|    fps                  | 312         |
|    iterations           | 288000      |
|    time_elapsed         | 921         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.015077358 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -1.01e-05   |
|    learning_rate        | 0.0001      |
|    loss                 | 537         |
|    n_updates            | 219         |
|    policy_gradient_loss | -0.00165    |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| policy_id               | 2           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -248        |
| time/                   |             |
|    fps                  | 309         |
|    iterations           | 288000      |
|    time_elapsed         | 930         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.011997533 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -6.91e-06   |
|    learning_rate        | 0.0001      |
|    loss                 | 561         |
|    n_updates            | 238         |
|    policy_gradient_loss | -0.00161    |
|    value_loss           | 1.18e+03    |
-----------------------------------------
Early stopping at step 14 due to reaching max kl: 0.02
-----------------------------------------
| policy_id               | 3           |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -240        |
| time/                   |             |
|    fps                  | 307         |
|    iterations           | 288000      |
|    time_elapsed         | 935         |
|    total_timesteps      | 288000      |
| train/                  |             |
|    approx_kl            | 0.009973342 |
|    clip_fraction        | 0.0193      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -4.77e-07   |
|    learning_rate        | 0.0001      |
|    loss                 | 597         |
|    n_updates            | 231         |
|    policy_gradient_loss | -0.00148    |
|    value_loss           | 1.2e+03     |
-----------------------------------------
